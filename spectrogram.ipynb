{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uo-gqj3P4jl",
        "outputId": "ea22188c-e25b-4b87-cf55-db6bf9f74d6c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"drive/MyDrive/audio_dataset.zip\""
      ],
      "metadata": {
        "id": "OJ-PtubsYWmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r \"audio_dataset/train/Laughter/.ipynb_checkpoints\""
      ],
      "metadata": {
        "id": "IOMCa38MQgnR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment"
      ],
      "metadata": {
        "id": "nWiNFuGsSU6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43627ff5-945c-4102-d296-f8312e62dfa5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_m4a(input_file):\n",
        "    with open(input_file, 'rb') as file:\n",
        "        header = file.read(20)\n",
        "        if b'\\x4D\\x34\\x41\\x20' in header:\n",
        "            sound = AudioSegment.from_file(input_file, format='m4a')\n",
        "            out_file = input_file.split('.')[0] + '.wav'\n",
        "            os.remove(input_file)\n",
        "            file_handle = sound.export(out_file, format='wav')\n",
        "            return out_file\n",
        "\n",
        "        return input_file"
      ],
      "metadata": {
        "id": "RHy488VoRulk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class conf:\n",
        "    sampling_rate = 30000\n",
        "    duration = 2\n",
        "    hop_length = 347*duration\n",
        "    fmin = 20\n",
        "    fmax = sampling_rate // 2\n",
        "    n_mels = 128\n",
        "    n_fft = n_mels * 20\n",
        "    samples = sampling_rate * duration"
      ],
      "metadata": {
        "id": "OMp4B1WvXgvc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jsobucIWZ9-D"
      },
      "outputs": [],
      "source": [
        "def create_spectrogram(audio_file, image_file):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
        "\n",
        "    y, sr = librosa.load(audio_file, sr = conf.sampling_rate)\n",
        "\n",
        "    if len(y) > conf.samples:\n",
        "        y = y[0:0+conf.samples]\n",
        "    else:\n",
        "        padding = conf.samples - len(y)\n",
        "        offset = padding // 2\n",
        "        y = np.pad(y, (offset, conf.samples - len(y) - offset), 'constant')\n",
        "\n",
        "    ms = librosa.feature.melspectrogram(y=y, sr=conf.sampling_rate, n_mels=conf.n_mels,\n",
        "                                        hop_length=conf.hop_length, n_fft=conf.n_fft,\n",
        "                                        fmin=conf.fmin, fmax=conf.fmax)\n",
        "    log_ms = librosa.power_to_db(ms, ref=np.max)\n",
        "    librosa.display.specshow(log_ms, sr=conf.sampling_rate)\n",
        "    log_ms = log_ms.astype(np.float32)\n",
        "    fig.savefig(image_file)\n",
        "    plt.close(fig)\n",
        "\n",
        "def create_pngs_from_wavs(input_path, output_path):\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "\n",
        "    dir = os.listdir(input_path)\n",
        "\n",
        "    for i, file in enumerate(dir):\n",
        "        input_file = os.path.join(input_path, file)\n",
        "        input_file = conv_m4a(input_file)\n",
        "        output_file = os.path.join(output_path, file+'.png')\n",
        "        create_spectrogram(input_file, output_file)\n",
        "        print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYe2x86bdUU5"
      },
      "outputs": [],
      "source": [
        "sounds = ['Laughter', 'car_horn', 'dog_barking', 'drilling', 'Fart', 'Guitar', 'Gunshot_and_gunfire', 'Hi-hat', 'Knock',\n",
        "          'Shatter', 'siren', 'Snare_drum', 'Splash_and_splatter']\n",
        "\n",
        "for sound in sounds:\n",
        "    input_path = f'audio_dataset/train/{sound}'\n",
        "    output_path = f'spectrograms/train/{sound}'\n",
        "    create_pngs_from_wavs(input_path, output_path)\n",
        "    print('Finished ', sound)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sounds = ['Laughter', 'car_horn', 'dog_barking', 'drilling', 'Fart', 'Guitar', 'Gunshot_and_gunfire', 'Hi-hat', 'Knock',\n",
        "          'Shatter', 'siren', 'Snare_drum', 'Splash_and_splatter']\n",
        "\n",
        "for sound in sounds:\n",
        "    input_path = f'audio_dataset/val/{sound}'\n",
        "    output_path = f'spectrograms/val/{sound}'\n",
        "    create_pngs_from_wavs(input_path, output_path)\n",
        "    print('Finished ', sound)"
      ],
      "metadata": {
        "id": "Sj51TTKlb1oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XKTqPVOgOWM"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "def load_images_from_path(path, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for file in os.listdir(path):\n",
        "        images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n",
        "        labels.append((label))\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "def show_images(images):\n",
        "    fig, axes = plt.subplots(1, 8, figsize=(20, 20), subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(images[i] / 255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSZWwVdigWGo"
      },
      "outputs": [],
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for sound in sounds:\n",
        "    images, labels = load_images_from_path(f'spectrograms/train/{sound}', sounds.index(sound))\n",
        "    x_train += images\n",
        "    y_train += labels\n",
        "\n",
        "for sound in sounds:\n",
        "    images, labels = load_images_from_path(f'spectrograms/val/{sound}', sounds.index(sound))\n",
        "    x_test += images\n",
        "    y_test += labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFIVyxMPg8uo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_encoded = to_categorical(y_train)\n",
        "y_test_encoded = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kANQacCJg-Hf"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, BatchNormalization, Dropout, Input\n",
        "import keras.regularizers as regularizers\n",
        "import keras.initializers as initializers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(num_channels):\n",
        "    block = Sequential([\n",
        "        Conv2D(num_channels, (3, 3), padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Activation('relu')\n",
        "    ])\n",
        "    return block\n",
        "\n",
        "def identity_block(num_channels):\n",
        "    block = Sequential([\n",
        "        conv_block(num_channels),\n",
        "        Conv2D(num_channels, (3, 3), padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Activation('relu')\n",
        "    ])\n",
        "    return block\n",
        "\n",
        "def res_block(num_channels, conv_first=False):\n",
        "    block = Sequential()\n",
        "    if conv_first:\n",
        "        block.add(Conv2D(num_channels, (1, 1), strides=(2, 2)))\n",
        "    block.add(conv_block(num_channels))\n",
        "    block.add(Conv2D(num_channels, (3, 3), padding='same'))\n",
        "    block.add(BatchNormalization())\n",
        "    return block"
      ],
      "metadata": {
        "id": "OpodhxiEW97H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q_qlOSBhCpO"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "            Input(shape=(224, 224, 3)),\n",
        "            Conv2D(64, (7, 7), strides=(2, 2), padding='same'),\n",
        "            BatchNormalization(),\n",
        "            Activation('relu'),\n",
        "            MaxPooling2D((3, 3), strides=(2, 2), padding='same')\n",
        "        ])\n",
        "num_channels = 64\n",
        "for i in range(3):\n",
        "    model.add(res_block(num_channels, conv_first=(i==0)))\n",
        "    num_channels *= 2\n",
        "for i in range(4):\n",
        "    model.add(identity_block(num_channels))\n",
        "for i in range(6):\n",
        "    model.add(identity_block(num_channels*2))\n",
        "for i in range(3):\n",
        "    model.add(identity_block(num_channels*4))\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(Dense(13, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYtJa34Bhfa4"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "hist = model.fit(x_train, y_train_encoded, validation_data=(x_test, y_test_encoded), batch_size=10, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkbdYYJJzy6H"
      },
      "outputs": [],
      "source": [
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, '-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, ':', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjYhNvEOhyJ5"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(np.array(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfW_MB63jnKT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "\n",
        "mat = confusion_matrix(y_test_encoded.argmax(axis=1), prediction.argmax(axis=1))\n",
        "class_labels = ['background', 'chainsaw', 'engine', 'storm']\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, cmap='Blues',\n",
        "            xticklabels=sounds,\n",
        "            yticklabels=sounds)\n",
        "\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('Actual label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMajz0k3kDSd"
      },
      "outputs": [],
      "source": [
        "precision_recall_fscore_support(y_test_encoded.argmax(axis=1), prediction.argmax(axis=1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}