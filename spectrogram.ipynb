{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uo-gqj3P4jl",
        "outputId": "ea22188c-e25b-4b87-cf55-db6bf9f74d6c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ-PtubsYWmO"
      },
      "outputs": [],
      "source": [
        "!unzip \"drive/MyDrive/audio_dataset.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOMCa38MQgnR"
      },
      "outputs": [],
      "source": [
        "!rm -r \"audio_dataset/train/Laughter/.ipynb_checkpoints\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWiNFuGsSU6R",
        "outputId": "130497ba-cd71-4721-d5dd-546069b13c99"
      },
      "outputs": [],
      "source": [
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSHqWhxMgYpE"
      },
      "outputs": [],
      "source": [
        "sounds = ['Laughter', 'car_horn', 'dog_barking', 'drilling', 'Fart', 'Guitar', 'Gunshot_and_gunfire', 'Hi-hat', 'Knock',\n",
        "          'Shatter', 'siren', 'Snare_drum', 'Splash_and_splatter']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHy488VoRulk"
      },
      "outputs": [],
      "source": [
        "def conv_m4a(input_file):\n",
        "    with open(input_file, 'rb') as file:\n",
        "        header = file.read(20)\n",
        "        if b'\\x4D\\x34\\x41\\x20' in header:\n",
        "            sound = AudioSegment.from_file(input_file, format='m4a')\n",
        "            out_file = input_file.split('.')[0] + '.wav'\n",
        "            os.remove(input_file)\n",
        "            file_handle = sound.export(out_file, format='wav')\n",
        "            return out_file\n",
        "\n",
        "        return input_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMp4B1WvXgvc"
      },
      "outputs": [],
      "source": [
        "class conf:\n",
        "    sampling_rate = 30000\n",
        "    duration = 2\n",
        "    hop_length = 347*duration\n",
        "    fmin = 20\n",
        "    fmax = sampling_rate // 2\n",
        "    n_mels = 128\n",
        "    n_fft = n_mels * 20\n",
        "    samples = sampling_rate * duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsobucIWZ9-D"
      },
      "outputs": [],
      "source": [
        "def create_spectrogram(audio_file, image_file):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
        "\n",
        "    y, sr = librosa.load(audio_file, sr = conf.sampling_rate)\n",
        "\n",
        "    if len(y) > conf.samples:\n",
        "        y = y[0:0+conf.samples]\n",
        "    else:\n",
        "        padding = conf.samples - len(y)\n",
        "        offset = padding // 2\n",
        "        y = np.pad(y, (offset, conf.samples - len(y) - offset), 'constant')\n",
        "\n",
        "    ms = librosa.feature.melspectrogram(y=y, sr=conf.sampling_rate, n_mels=conf.n_mels,\n",
        "                                        hop_length=conf.hop_length, n_fft=conf.n_fft,\n",
        "                                        fmin=conf.fmin, fmax=conf.fmax)\n",
        "    log_ms = librosa.power_to_db(ms, ref=np.max)\n",
        "    librosa.display.specshow(log_ms, sr=conf.sampling_rate)\n",
        "    log_ms = log_ms.astype(np.float32)\n",
        "    fig.savefig(image_file)\n",
        "    plt.close(fig)\n",
        "\n",
        "def create_pngs_from_wavs(input_path, output_path):\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "\n",
        "    dir = os.listdir(input_path)\n",
        "\n",
        "    for i, file in enumerate(dir):\n",
        "        input_file = os.path.join(input_path, file)\n",
        "        input_file = conv_m4a(input_file)\n",
        "        output_file = os.path.join(output_path, file+'.png')\n",
        "        create_spectrogram(input_file, output_file)\n",
        "        print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYe2x86bdUU5"
      },
      "outputs": [],
      "source": [
        "for sound in sounds:\n",
        "    input_path = f'audio_dataset/train/{sound}'\n",
        "    output_path = f'spectrograms/train/{sound}'\n",
        "    create_pngs_from_wavs(input_path, output_path)\n",
        "    print('Finished ', sound)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj51TTKlb1oL"
      },
      "outputs": [],
      "source": [
        "for sound in sounds:\n",
        "    input_path = f'audio_dataset/val/{sound}'\n",
        "    output_path = f'spectrograms/val/{sound}'\n",
        "    create_pngs_from_wavs(input_path, output_path)\n",
        "    print('Finished ', sound)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsrTl8m4uEV5"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "def load_images_from_path(path, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    dirs = os.listdir(path)\n",
        "    for file in dirs:\n",
        "        img = image.load_img(os.path.join(path, file), target_size=(224, 224))\n",
        "        img_array = image.img_to_array(img)\n",
        "        images.append(img_array)\n",
        "        labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "def load_data(paths, labels):\n",
        "    images = []\n",
        "    labels_list = []\n",
        "    for path, label in zip(paths, labels):\n",
        "        loaded_images, loaded_labels = load_images_from_path(path, label)\n",
        "        images.extend(loaded_images)\n",
        "        labels_list.extend(loaded_labels)\n",
        "    return np.array(images), np.array(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0fOyS-wuKoN"
      },
      "outputs": [],
      "source": [
        "train_paths = [f'spectrograms/train/{sound}' for sound in sounds]\n",
        "val_paths = [f'spectrograms/val/{sound}' for sound in sounds]\n",
        "\n",
        "x_train, y_train = load_data(train_paths, range(len(sounds)))\n",
        "x_test, y_test = load_data(val_paths, range(len(sounds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFIVyxMPg8uo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_encoded = to_categorical(y_train)\n",
        "y_test_encoded = to_categorical(y_test)\n",
        "del y_train\n",
        "del y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r5VfJ_Ku1vq",
        "outputId": "bcabd5b0-a536-493c-aa45-a2702cfa3c52"
      },
      "outputs": [],
      "source": [
        "(len(x_test), len(y_test_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9glLWVvYmrXK"
      },
      "outputs": [],
      "source": [
        "# x_train = np.array(x_train)\n",
        "# x_test = np.array(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kANQacCJg-Hf"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, BatchNormalization, Dropout, Input\n",
        "import keras.regularizers as regularizers\n",
        "import keras.initializers as initializers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpodhxiEW97H"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def conv_block(input_tensor, num_channels, strides=(1, 1)):\n",
        "    x = layers.Conv2D(num_channels, (1, 1), strides=strides)(input_tensor)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(num_channels, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(num_channels * 4, (1, 1))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    shortcut = layers.Conv2D(num_channels * 4, (1, 1), strides=strides)(input_tensor)\n",
        "    shortcut = layers.BatchNormalization()(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def identity_block(input_tensor, num_channels):\n",
        "    x = layers.Conv2D(num_channels, (1, 1))(input_tensor)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(num_channels, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(num_channels * 4, (1, 1))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def resnet50(input_shape=(224, 224, 3), classes=13):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.ZeroPadding2D((3, 3))(inputs)\n",
        "    x = layers.Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D((1, 1))(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 64, strides=(1, 1))\n",
        "    x = identity_block(x, 64)\n",
        "    x = identity_block(x, 64)\n",
        "\n",
        "    x = conv_block(x, 128)\n",
        "    x = identity_block(x, 128)\n",
        "    x = identity_block(x, 128)\n",
        "    x = identity_block(x, 128)\n",
        "\n",
        "    x = conv_block(x, 256)\n",
        "    x = identity_block(x, 256)\n",
        "    x = identity_block(x, 256)\n",
        "    x = identity_block(x, 256)\n",
        "    x = identity_block(x, 256)\n",
        "    x = identity_block(x, 256)\n",
        "\n",
        "    x = conv_block(x, 512)\n",
        "    x = identity_block(x, 512)\n",
        "    x = identity_block(x, 512)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, x)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q_qlOSBhCpO"
      },
      "outputs": [],
      "source": [
        "# model = Sequential([\n",
        "#             Input(shape=(224, 224, 3)),\n",
        "#             Conv2D(64, (7, 7), strides=(2, 2), padding='same'),\n",
        "#             BatchNormalization(),\n",
        "#             Activation('relu'),\n",
        "#             MaxPooling2D((3, 3), strides=(2, 2), padding='same')\n",
        "#         ])\n",
        "# num_channels = 64\n",
        "# for i in range(3):\n",
        "#     model.add(res_block(num_channels, conv_first=(i==0)))\n",
        "#     num_channels *= 2\n",
        "# for i in range(4):\n",
        "#     model.add(identity_block(num_channels))\n",
        "# for i in range(6):\n",
        "#     model.add(identity_block(num_channels*2))\n",
        "# for i in range(3):\n",
        "#     model.add(identity_block(num_channels*4))\n",
        "# model.add(layers.GlobalAveragePooling2D())\n",
        "# model.add(Dense(13, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYhGDt7gxsBl",
        "outputId": "ee7cf804-8060-48dc-f254-755eebedad77"
      },
      "outputs": [],
      "source": [
        "model = resnet50()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYtJa34Bhfa4",
        "outputId": "fa32722a-c7e7-436e-ffed-f2988467c3ee"
      },
      "outputs": [],
      "source": [
        "hist = model.fit(x_train, y_train_encoded, validation_data=(x_test, y_test_encoded), batch_size=5, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkbdYYJJzy6H"
      },
      "outputs": [],
      "source": [
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, '-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, ':', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjYhNvEOhyJ5"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfW_MB63jnKT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "\n",
        "mat = confusion_matrix(y_test_encoded.argmax(axis=1), prediction.argmax(axis=1))\n",
        "class_labels = ['background', 'chainsaw', 'engine', 'storm']\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, cmap='Blues',\n",
        "            xticklabels=sounds,\n",
        "            yticklabels=sounds)\n",
        "\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('Actual label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMajz0k3kDSd"
      },
      "outputs": [],
      "source": [
        "precision_recall_fscore_support(y_test_encoded.argmax(axis=1), prediction.argmax(axis=1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
